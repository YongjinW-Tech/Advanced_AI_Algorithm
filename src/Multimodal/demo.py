#!/usr/bin/env python
"""
å¤šæ¨¡æ€CLIPè®­ç»ƒæ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•å¿«é€Ÿå¼€å§‹ä½¿ç”¨å¤šæ¨¡æ€CLIPè®­ç»ƒç³»ç»Ÿã€‚
å®ƒä¼šåˆ›å»ºç¤ºä¾‹æ•°æ®ã€è¿è¡Œä¸€ä¸ªç®€çŸ­çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶å±•ç¤ºç»“æœã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python demo.py
"""

import os
import sys
import torch
import numpy as np
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_loader import create_sample_dataset, create_data_loaders
from clip_model import create_model_and_optimizer, ContrastiveLoss, MultimodalTrainer
from evaluation import ModelEvaluator
from visualization import TrainingVisualizer


def run_demo():
    """è¿è¡Œå®Œæ•´çš„æ¼”ç¤º"""
    
    print("=" * 60)
    print("ğŸš€ å¤šæ¨¡æ€CLIPè®­ç»ƒæ¼”ç¤º")
    print("=" * 60)
    
    # è®¾ç½®æ¼”ç¤ºå‚æ•°
    demo_config = {
        'data_dir': './demo_data',
        'results_dir': './demo_results',
        'num_samples': 50,  # æ¼”ç¤ºç”¨å°‘é‡æ•°æ®
        'batch_size': 8,
        'num_epochs': 5,    # æ¼”ç¤ºç”¨å°‘é‡è½®æ¬¡
        'learning_rate': 1e-4,
        'model_name': 'ViT-B/32'
    }
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ­¥éª¤1: åˆ›å»ºæ¼”ç¤ºæ•°æ®
    print(f"\nğŸ“Š æ­¥éª¤1: åˆ›å»ºæ¼”ç¤ºæ•°æ® ({demo_config['num_samples']} ä¸ªæ ·æœ¬)")
    
    if not os.path.exists(demo_config['data_dir']):
        os.makedirs(demo_config['data_dir'], exist_ok=True)
        create_sample_dataset(demo_config['data_dir'], demo_config['num_samples'])
        print("âœ… æ¼”ç¤ºæ•°æ®åˆ›å»ºå®Œæˆ")
    else:
        print("âœ… æ¼”ç¤ºæ•°æ®å·²å­˜åœ¨")
    
    # æ­¥éª¤2: åŠ è½½æ•°æ®
    print(f"\nğŸ“¥ æ­¥éª¤2: åŠ è½½æ•°æ®")
    try:
        train_loader, val_loader = create_data_loaders(
            demo_config['data_dir'],
            batch_size=demo_config['batch_size'],
            num_workers=2  # æ¼”ç¤ºç”¨è¾ƒå°‘è¿›ç¨‹
        )
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ - è®­ç»ƒé›†: {len(train_loader)} æ‰¹æ¬¡, éªŒè¯é›†: {len(val_loader)} æ‰¹æ¬¡")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ­¥éª¤3: åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ¤– æ­¥éª¤3: åˆ›å»ºæ¨¡å‹ ({demo_config['model_name']})")
    try:
        model, optimizer = create_model_and_optimizer(
            model_name=demo_config['model_name'],
            learning_rate=demo_config['learning_rate'],
            device=device
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        criterion = ContrastiveLoss()
        trainer = MultimodalTrainer(
            model=model,
            optimizer=optimizer,
            criterion=criterion,
            device=device
        )
        
        print("âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ")
        
        # æ¨¡å‹å‚æ•°ç»Ÿè®¡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"ğŸ“ˆ æ¨¡å‹å‚æ•°: æ€»è®¡ {total_params:,}, å¯è®­ç»ƒ {trainable_params:,}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # æ­¥éª¤4: è®­ç»ƒæ¼”ç¤º
    print(f"\nğŸ”¥ æ­¥éª¤4: å¼€å§‹è®­ç»ƒ ({demo_config['num_epochs']} è½®)")
    
    train_history = []
    val_history = []
    
    try:
        for epoch in range(demo_config['num_epochs']):
            print(f"\n--- è½®æ¬¡ {epoch + 1}/{demo_config['num_epochs']} ---")
            
            # è®­ç»ƒä¸€ä¸ªepoch
            model.train()
            epoch_losses = []
            epoch_accs = []
            
            for batch_idx, (images, texts) in enumerate(train_loader):
                images = images.to(device)
                texts = texts.to(device)
                
                # è®­ç»ƒæ­¥éª¤
                metrics = trainer.train_step(images, texts)
                epoch_losses.append(metrics['total_loss'])
                epoch_accs.append(metrics['i2t_acc1'])
                
                if batch_idx == 0:  # åªæ‰“å°ç¬¬ä¸€ä¸ªbatchçš„è¯¦ç»†ä¿¡æ¯
                    print(f"  æ‰¹æ¬¡ {batch_idx + 1}: æŸå¤±={metrics['total_loss']:.4f}, "
                          f"I2Tå‡†ç¡®ç‡={metrics['i2t_acc1']:.4f}")
            
            # è®°å½•è®­ç»ƒæŒ‡æ ‡
            train_metrics = {
                'total_loss': np.mean(epoch_losses),
                'i2t_acc1': np.mean(epoch_accs),
                'loss_i2t': np.mean(epoch_losses),  # ç®€åŒ–æ¼”ç¤º
                'loss_t2i': np.mean(epoch_losses),
                'i2t_acc5': np.mean(epoch_accs) + 0.1,  # æ¨¡æ‹Ÿ
                't2i_acc1': np.mean(epoch_accs) - 0.02,
                't2i_acc5': np.mean(epoch_accs) + 0.08,
                'logit_scale': 14.0
            }
            train_history.append(train_metrics)
            
            # éªŒè¯
            if epoch % 2 == 0:  # æ¯2è½®éªŒè¯ä¸€æ¬¡
                model.eval()
                val_losses = []
                val_accs = []
                
                with torch.no_grad():
                    for images, texts in val_loader:
                        images = images.to(device)
                        texts = texts.to(device)
                        
                        metrics = trainer.validate_step(images, texts)
                        val_losses.append(metrics['total_loss'])
                        val_accs.append(metrics['i2t_acc1'])
                
                val_metrics = {
                    'total_loss': np.mean(val_losses),
                    'i2t_acc1': np.mean(val_accs),
                    'loss_i2t': np.mean(val_losses),
                    'loss_t2i': np.mean(val_losses),
                    'i2t_acc5': np.mean(val_accs) + 0.08,
                    't2i_acc1': np.mean(val_accs) - 0.03,
                    't2i_acc5': np.mean(val_accs) + 0.05,
                    'logit_scale': 14.0
                }
                val_history.append(val_metrics)
                
                print(f"  éªŒè¯: æŸå¤±={val_metrics['total_loss']:.4f}, "
                      f"å‡†ç¡®ç‡={val_metrics['i2t_acc1']:.4f}")
        
        print("âœ… è®­ç»ƒå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return
    
    # æ­¥éª¤5: æ¨¡å‹è¯„ä¼°
    print(f"\nğŸ“Š æ­¥éª¤5: æ¨¡å‹è¯„ä¼°")
    try:
        evaluator = ModelEvaluator(model, device)
        
        # ç®€åŒ–è¯„ä¼°ï¼ˆç”¨éªŒè¯é›†ï¼‰
        final_metrics = {}
        if val_loader:
            # æ”¶é›†ä¸€äº›ç‰¹å¾ç”¨äºè¯„ä¼°
            all_image_features = []
            all_text_features = []
            
            model.eval()
            with torch.no_grad():
                for i, (images, texts) in enumerate(val_loader):
                    if i >= 3:  # åªç”¨å‰3ä¸ªæ‰¹æ¬¡åšæ¼”ç¤º
                        break
                    images = images.to(device)
                    texts = texts.to(device)
                    
                    image_features = model.encode_image(images)
                    text_features = model.encode_text(texts)
                    
                    all_image_features.append(image_features.cpu())
                    all_text_features.append(text_features.cpu())
            
            if all_image_features:
                all_image_features = torch.cat(all_image_features, dim=0)
                all_text_features = torch.cat(all_text_features, dim=0)
                
                # è®¡ç®—æ£€ç´¢æŒ‡æ ‡
                final_metrics = evaluator.compute_retrieval_metrics(
                    all_image_features, all_text_features
                )
                
                print("ğŸ¯ è¯„ä¼°ç»“æœ:")
                print(f"  å›¾åƒâ†’æ–‡æœ¬ R@1: {final_metrics['i2t_r1']:.2f}%")
                print(f"  å›¾åƒâ†’æ–‡æœ¬ R@5: {final_metrics['i2t_r5']:.2f}%")
                print(f"  æ–‡æœ¬â†’å›¾åƒ R@1: {final_metrics['t2i_r1']:.2f}%")
                print(f"  æ–‡æœ¬â†’å›¾åƒ R@5: {final_metrics['t2i_r5']:.2f}%")
                print(f"  æ€»åˆ† RSum: {final_metrics['rsum']:.2f}")
        
        print("âœ… è¯„ä¼°å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        final_metrics = {}
    
    # æ­¥éª¤6: ç»“æœå¯è§†åŒ–
    print(f"\nğŸ“ˆ æ­¥éª¤6: ç”Ÿæˆå¯è§†åŒ–ç»“æœ")
    try:
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(demo_config['results_dir'], exist_ok=True)
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = TrainingVisualizer(demo_config['results_dir'])
        
        # ç”Ÿæˆè®­ç»ƒæ›²çº¿
        if train_history and val_history:
            visualizer.plot_training_curves(train_history, val_history, "demo_training_curves.png")
        
        # ç”ŸæˆæŒ‡æ ‡å›¾
        if final_metrics:
            visualizer.plot_model_metrics(final_metrics, "demo_metrics.png")
        
        # ç”ŸæˆæŸå¤±åˆ†æ
        if train_history:
            visualizer.plot_loss_components(train_history, "demo_loss_components.png")
        
        print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {demo_config['results_dir']}")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    # æ­¥éª¤7: ä¿å­˜æ¼”ç¤ºç»“æœ
    print(f"\nğŸ’¾ æ­¥éª¤7: ä¿å­˜æ¼”ç¤ºç»“æœ")
    try:
        import json
        
        demo_summary = {
            "æ¼”ç¤ºæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "é…ç½®": demo_config,
            "è®¾å¤‡": device,
            "æœ€ç»ˆæ€§èƒ½": final_metrics,
            "è®­ç»ƒå†å²é•¿åº¦": len(train_history),
            "éªŒè¯å†å²é•¿åº¦": len(val_history)
        }
        
        summary_path = os.path.join(demo_config['results_dir'], "demo_summary.json")
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(demo_summary, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æ¼”ç¤ºæ€»ç»“å·²ä¿å­˜åˆ°: {summary_path}")
        
    except Exception as e:
        print(f"âŒ ç»“æœä¿å­˜å¤±è´¥: {e}")
    
    # å®Œæˆæ¼”ç¤º
    print("\n" + "=" * 60)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print("=" * 60)
    
    print(f"\nğŸ“ æŸ¥çœ‹ç»“æœ:")
    print(f"  æ¼”ç¤ºæ•°æ®: {demo_config['data_dir']}")
    print(f"  ç»“æœæ–‡ä»¶: {demo_config['results_dir']}")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥:")
    print(f"  1. å‡†å¤‡çœŸå®çš„å›¾åƒ-æ–‡æœ¬å¯¹æ•°æ®")
    print(f"  2. è°ƒæ•´é…ç½®å‚æ•° (batch_size, learning_rateç­‰)")
    print(f"  3. è¿è¡Œå®Œæ•´è®­ç»ƒ: python train.py")
    print(f"  4. æŸ¥çœ‹è¯¦ç»†çš„README.mdäº†è§£æ›´å¤šåŠŸèƒ½")
    

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    run_demo()
