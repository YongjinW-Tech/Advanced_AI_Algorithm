该路径下包含四个任务：

## 任务

1. **词表示**：训练一个 Word2Vec 词嵌入模型，理解词向量的生成与语义捕捉。

2. **句子表示**：使用 BERT 预训练模型，提取句子级别的向量表示，感受上下文语义的编码能力。

3. **生成模型**：利用 OPT 模型进行文本生成实验，掌握 Next Token Prediction 原理。

4. **多模态训练**：尝试基于文本 - 图像对数据，微调增强 CLIP 模型的跨模态表示学习能力。


## 任务理解

1. 词表示（Word2Vec）
    - 核心思想：通过预测一个词的上下文（Skip-Gram）或预测中心词（CBOW），学习到每个词的低维稠密向量。
	- 理解重点：
	    - 词向量的分布式表示（避免稀疏的 one-hot）。
	    - 语义捕捉：相似词的向量接近（如 king - man + woman ≈ queen）。
	- 目的：感受词语层面如何通过统计与预测建立语义空间。

2. 句子表示（BERT）
    - 核心思想：基于 Transformer 的双向编码器，通过大规模预训练（Masked Language Modeling + Next Sentence Prediction）获得上下文感知的表示。
	- 理解重点：
	    - 不再是词的固定向量，而是动态上下文相关的向量。
	    - 提取 [CLS] 向量或池化后的句子表示，理解“句子级别语义编码”。/Users/wyjtech/learningspace/Advanced_AI_Algorithm/src/From_Word_to_Multimodal
	- 目的：体验深度预训练模型如何解决词义歧义、捕捉长距离依赖。

3. 生成模型（OPT）
	- 核心思想：基于自回归 Transformer，采用 Next Token Prediction（预测下一个词），适合生成流畅的文本。
	- 理解重点：
	    - 与 BERT 相比，OPT 只做单向预测，但更适合生成。
	    - 学习“语言模型是如何逐词生成”的机制。
	- 目的：直观体验“语言模型作为生成器”的能力。

4. 多模态训练（CLIP）
	- 核心思想：同时编码图像和文本，使两者在同一向量空间中对齐，通过对比学习实现跨模态表示。
	- 理解重点：
	    - 文本与图像的相互对齐：同一图像和描述的表示接近，不同则远离。
	    - 通过微调增强跨模态任务的能力（如图文检索、分类）。
	- 目的：理解多模态表示学习的基本框架，体会从单模态（词/句子/文本）走向跨模态的扩展。

### 总体理解

这四个任务构成了一个由浅入深的学习路线：
1. 从词到句子 → 学习基本的语义表示。
2. 从表达到生成 → 理解语言模型的核心预测机制。
3.	从单模态到多模态 → 探索跨模态表示和应用。

一条“AI 表示学习 + 生成”的成长路径：**局部（词） → 全局（句子） → 生成（语言模型） → 跨模态（文本+图像）**。